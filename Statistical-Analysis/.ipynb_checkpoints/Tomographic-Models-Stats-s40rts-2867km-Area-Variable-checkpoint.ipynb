{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'C:/Users/annal/OneDrive/Documents/python3.8/pygplates_rev28_python38_win64')\n",
    "# sys.path.insert(0,'/Users/omer/Documents/pygplates_rev18_python27_MacOS64')\n",
    "sys.path.insert(0,'/Users/omer/Documents/pygplates_rev28_python38_MacOS64/')\n",
    "sys.path.insert(1,'/Applications/GMT-6.0.0.app/Contents/Resources')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install healpy \n",
    "# !pip instadll statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygplates\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import sphere_tools as sph\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import sys\n",
    "from matplotlib.lines import Line2D\n",
    "from call_system_command import call_system_command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_number_of_LIPs(age,window,point_features):\n",
    "    \n",
    "    agemax = age+window\n",
    "    agemin = age-window\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for p in point_features:\n",
    "        \n",
    "        # NB valid_time is a tuple, we take the first value since this is the 'birth' time of the LIP\n",
    "        BirthTime = p.get_valid_time()[0] \n",
    "        \n",
    "        if BirthTime <= agemax and BirthTime > agemin:\n",
    "            \n",
    "            count+=1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volcanic_product_long_lat(rotations,anchor_plate_id,age,window,point_features):\n",
    "    \n",
    "    agemax = age+window\n",
    "    agemin = age-window\n",
    "    \n",
    "    Xr = []\n",
    "    Yr = []\n",
    "\n",
    "    for p in point_features:\n",
    "        \n",
    "        # NB valid_time is a tuple, we take the first value since this is the 'birth' time of the Kimberlite\n",
    "        BirthTime = p.get_valid_time()[0] \n",
    "        \n",
    "        if BirthTime <= agemax and BirthTime > agemin:\n",
    "            \n",
    "            PlateID = p.get_reconstruction_plate_id()\n",
    "\n",
    "            # Get rotation for the point and reconstruct to its birth time if it's in age interval (window)\n",
    "            Kimb_rotation = rotations.get_rotation(age, PlateID, anchor_plate_id)\n",
    "\n",
    "            reconstructed_point = Kimb_rotation * p.get_geometry()\n",
    "            reconstructed_point_degrees = reconstructed_point.to_lat_lon_point()\n",
    "\n",
    "            Xr.append(reconstructed_point_degrees.get_longitude())\n",
    "            Yr.append(reconstructed_point_degrees.get_latitude())\n",
    "    \n",
    "    \n",
    "    return Xr, Yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function to sample grids using grdtrack and read results\n",
    "def sample_using_gmt(grdfile, point_lons, point_lats,OutputDirectory):\n",
    "\n",
    "        dataout = np.vstack((np.asarray(point_lons),np.asarray(point_lats))).T\n",
    "\n",
    "        np.savetxt(OutputDirectory+'/tmp.txt',dataout)\n",
    "        \n",
    "        # Note -nn forces nearest neighbour interpolation\n",
    "        call_system_command(['gmt',\n",
    "                             'grdtrack',\n",
    "                             '%s/tmp.txt' %OutputDirectory,\n",
    "                             '-G{:s}'.format(grdfile), \n",
    "                             '-fg',\n",
    "                             '-nn',\n",
    "                             '-V',\n",
    "                             '>', \n",
    "                             '%s/tmp_interp.txt' % OutputDirectory])\n",
    "        G=[]\n",
    "        with open(OutputDirectory+'/tmp_interp.txt') as f:\n",
    "            for line in f:\n",
    "                if line[0] == '>':\n",
    "                    continue\n",
    "                else:\n",
    "                    tmp = line.split()\n",
    "                    G.append(float(tmp[2]))\n",
    "\n",
    "        f.close()\n",
    "        return np.array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_hot_nc_file(GridDirect,OutputDirect,TomogModelName,percentContourValue,Ma):\n",
    "    \n",
    "    StringFormContour=str(percentContourValue)\n",
    "    GridFile=\"%s/%s.nc\" %(GridDirect,TomogModelName)\n",
    "    MaString=str(Ma)\n",
    "    ContourFile=\"%s/%s_Contour_%s.txt\" %(OutputDirect,TomogModelName,StringFormContour)\n",
    "    TempGrid1=\"%s/%s_TempGrid1_%s.nc\" %(OutputDirect,TomogModelName,StringFormContour)\n",
    "    TempGrid2=\"%s/%s_TempGrid2_%s.nc\" %(OutputDirect,TomogModelName,StringFormContour)\n",
    "    hot_xyz_file=\"%s/%s_hot_%s_AreaVaried.xyz\" %(OutputDirect,TomogModelName,MaString)\n",
    "    \n",
    "    DistanceFROMHot=\"%s/%s_Distance_to_Hot_%s_AreaVaried.nc\" %(OutputDirect,TomogModelName,MaString)\n",
    "    \n",
    "    \n",
    "    percentContourValueLow=percentContourValue-0.001\n",
    "    percentContourValueHigh=percentContourValue+0.001\n",
    "    \n",
    "    print(str(percentContourValueLow),str(percentContourValueHigh))\n",
    "    call_system_command(['gmt',\n",
    "                     'grdcontour',\n",
    "                     GridFile,\n",
    "                     '-D%s' % ContourFile,\n",
    "                     '-C1',\n",
    "                     '-L/%s/%s' % (str(percentContourValueLow),str(percentContourValueHigh))])\n",
    "#     '-L/-0.303/-0.297'])    \n",
    "    call_system_command(['gmt',\n",
    "                      'grdclip',\n",
    "                     GridFile,\n",
    "                     '-Rd',\n",
    "                     '-Sa%.1f/1' % percentContourValue,\n",
    "                     '-G%s' % TempGrid1])\n",
    "    \n",
    "    call_system_command(['gmt',\n",
    "                      'grdclip',\n",
    "                     TempGrid1,\n",
    "                     '-Rd',\n",
    "                     '-Sb1/0',\n",
    "                     '-G%s' % TempGrid2])\n",
    "    \n",
    "    \n",
    "    call_system_command(['gmt',\n",
    "                         'grd2xyz',\n",
    "                         TempGrid2,\n",
    "                         '-Rd',\n",
    "                         '-di1',  # set all cells with '1' to be nodata\n",
    "                         '-s',\n",
    "                         '>',\n",
    "                         '%s' % hot_xyz_file])\n",
    "\n",
    "    call_system_command(['gmt',\n",
    "                         'grdmath',\n",
    "                         TempGrid2,\n",
    "                         '%s' % hot_xyz_file,\n",
    "                         'PDIST',\n",
    "                         'KM2DEG',\n",
    "                         '=',\n",
    "                         '%s' % DistanceFROMHot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import array of contour values and corresponding area coverage values for different tomographic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContoursVariable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ContoursVariable\n",
       "0               -1.50\n",
       "1               -1.49\n",
       "2               -1.48\n",
       "3               -1.47\n",
       "4               -1.46\n",
       "..                ...\n",
       "195              0.45\n",
       "196              0.46\n",
       "197              0.47\n",
       "198              0.48\n",
       "199              0.49\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AreasFors40rts = pd.read_csv(\"/Users/omer/Desktop/NatGeoReviews/AreasFors40rts_2867km.csv\",header=None,\n",
    "                             names=[\"AreasFors40rts\"])\n",
    "\n",
    "ContoursFors40rts= pd.read_csv(\"/Users/omer/Desktop/NatGeoReviews/Contours_Variable.csv\",header=None,\n",
    "                             names=[\"ContoursVariable\"])\n",
    "\n",
    "ContoursFors40rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case1Areas=np.asarray([47.9726287635,42.4100552434,43.2824677183,45.6569380355,46.9831730172,\n",
    "                      45.5868344616,45.7716162117,41.5415651999,39.9509147286])\n",
    "\n",
    "TimesForCase1Areas=np.asarray([200,180,160,140,120,100,80,60,40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AreasFors40rtsNP=AreasFors40rts.to_numpy()\n",
    "ContoursFors40rtsNP=ContoursFors40rts.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 200  Ma\n",
      "0.1600000000000014\n",
      "0.1590000000000014 0.1610000000000014\n",
      "1\n",
      "1 180  Ma\n",
      "0.0400000000000013\n",
      "0.0390000000000013 0.0410000000000013\n"
     ]
    }
   ],
   "source": [
    "GridDirect=\"/Users/omer/Desktop/NatGeoReviews/Tomographic-Models/s40rts/\"\n",
    "OutputDirect=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/s40rts/2867km/\"\n",
    "TomogModel=\"s40rts_2867\"\n",
    "\n",
    "\n",
    "for index in np.linspace(0,8,9,dtype=int):\n",
    "    print(index)\n",
    "    print(index, TimesForCase1Areas[index], \" Ma\")\n",
    "  \n",
    "    myindex=min(range(len(AreasFors40rtsNP)), key=lambda i: abs(AreasFors40rtsNP[i]-[Case1Areas[index]/100.]))\n",
    "    ContourToUse=ContoursFors40rtsNP[myindex]\n",
    "    print(float(ContourToUse))\n",
    "    ContourToUse=float(ContourToUse)\n",
    "#     \"%s%s.nc\" %(GridDirect,TomogModel)\n",
    "    create_hot_nc_file(GridDirect,OutputDirect,TomogModel,ContourToUse,TimesForCase1Areas[index])\n",
    "    \n",
    "# \"%s%s.nc\" %(GridDirect,TomogModel)\n",
    "# create_hot_nc_file(GridDirect,OutputDirect,TomogModel,-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistanceFROMHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_sampling(nPoints,age,dist_to_hot_nc_file,CalcOutputDir):\n",
    "    \n",
    "#     recon_label = '2017NNR'\n",
    "\n",
    "#     basedir='/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/M21NNR/NNR/NNR_InFiles/'\n",
    "#     input_rotation_filename1 = '%s/1000-410_rotations-NNR.rot' % basedir\n",
    "#     input_rotation_filename2 = '%s/Global_EB_410-250Ma_GK07_2017-NNR.rot' % basedir\n",
    "#     input_rotation_filename3 = '%s/Global_EB_250-0Ma_GK07_2017-NNR.rot' % basedir\n",
    "#     input_rotation_filename4 = '%s/NR_0Ma_1000Ma_for_gplates.rot' % basedir\n",
    "#     rotation_model = pygplates.RotationModel([input_rotation_filename1,input_rotation_filename2,\\\n",
    "#                                               input_rotation_filename3,input_rotation_filename4])\n",
    "\n",
    "#     ANCHOR_ID = int(0)\n",
    "#     cratonFileDir='/Users/omer/Documents/Programming/PyGplates/Supplement/Reconstructions/M21NNR/'\n",
    "#     cratonFile=cratonFileDir+\"shapes_cratons_Merdith_et_al.gpml\"\n",
    "    \n",
    "#     cratonFileDir='/Users/omer/Documents/Programming/PyGplates/Supplement/Reconstructions/NewCratonsForAnalysis/'\n",
    "#     cratonFile=cratonFileDir+\"cratons_150km_thick_with_plate_IDs_manually_edited.gpml\"\n",
    "    age=int(age)\n",
    "    recon_label = 'M21'\n",
    "    ReconstructionDir='/Users/omer/Desktop/NatGeoReviews/Reconstruction_Models/M21/'\n",
    "    cratonFile=ReconstructionDir+\"shapes_cratons_Merdith_et_al.gpml\"\n",
    "    cratons = pygplates.FeatureCollection(cratonFile)    \n",
    "\n",
    "    input_rotation_filename = '%s/1000_0_rotfile_Merdith_et_al.rot' % ReconstructionDir\n",
    "    ANCHOR_ID = int(0)\n",
    "    \n",
    "    rotation_model=pygplates.RotationModel(input_rotation_filename)\n",
    "\n",
    "    randomLons = []\n",
    "    randomLats = []\n",
    "    random_pdist2hot = []\n",
    "   \n",
    "    \n",
    "    # Start with an empty list of features\n",
    "    features_to_modify = []\n",
    "    new_features=[]\n",
    "    reconstructed_feature_geometries=[]\n",
    "    \n",
    "    # Reconstruct cratonic shapes at Age Ma\n",
    "    pygplates.reconstruct(cratons, rotation_model, reconstructed_feature_geometries, age)\n",
    "    \n",
    "#     print(reconstructed_feature_geometries)\n",
    "#     print(age)\n",
    "    \n",
    "    RandomPoints_Lats=np.array([])\n",
    "    RandomPoints_Lons=np.array([])\n",
    "    \n",
    "    totalRandomInsideCratons=0\n",
    "    \n",
    "    while(totalRandomInsideCratons<nPoints):\n",
    "        random_point = sph.random_points_feature(1)\n",
    "        for mp in random_point:\n",
    "            for point in mp.get_geometry().get_points():\n",
    "                pointInDegrees=point.to_lat_lon_point()\n",
    "                PointLat=pointInDegrees.get_latitude()\n",
    "                PointLon=pointInDegrees.get_longitude()\n",
    "                \n",
    "#                 for static_polygon in cratons:\n",
    "                for static_polygon in reconstructed_feature_geometries:\n",
    "#                     PlateID = static_polygon.get_reconstruction_plate_id()\n",
    "#                     static_polygon_geom = static_polygon.get_geometry()\n",
    "                    static_polygon_geom = static_polygon.get_reconstructed_geometry()\n",
    "                    if static_polygon_geom != None:\n",
    "                        if static_polygon_geom.is_point_in_polygon((PointLat,PointLon)):        \n",
    "#                             print(\"inside\")\n",
    "                            RandomPoints_Lats=np.append(RandomPoints_Lats,PointLat)\n",
    "                            RandomPoints_Lons=np.append(RandomPoints_Lons,PointLon)\n",
    "                            totalRandomInsideCratons=totalRandomInsideCratons+1\n",
    "                            cF=pygplates.Feature()\n",
    "                            cF.set_geometry(point)\n",
    "                            new_features.append(cF)\n",
    "    output_feature_collection = pygplates.FeatureCollection(new_features)\n",
    "    output_feature_collection.write(\"Random_\"+str(nPoints)+\"_Points_onCratons_Fors40rts_\"+str(age)+\"_Ma.gpml\")\n",
    "\n",
    "    # for the point locations of interest, sample the distance grids\n",
    "    # (and the original cluster boolean grid as a sanity check)\n",
    "    random_pdist2hot = sample_using_gmt(dist_to_hot_nc_file, RandomPoints_Lons, RandomPoints_Lats,CalcOutputDir)\n",
    "#     random_cluster_bool = sample_using_gmt(cluster_nc_file, RandomPoints_Lons, RandomPoints_Lats)\n",
    "    \n",
    "    return random_pdist2hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_feature_geometries=[]\n",
    "# pygplates.reconstruct(cratons, rotation_model, reconstructed_feature_geometries, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_feature_geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/'\n",
    "# grid_dir = '/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/'\n",
    "# solid_plot_dir = '/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/solid'\n",
    "KimberlitesFile='/Users/omer/Desktop/NatGeoReviews/Kimberlites/Tappe-et-al-2018-EPSL-Kimberlite_emplacement_ages-automatic-part1-with-locations-with-plate-IDs.gpml'\n",
    "pc = pygplates.FeatureCollection(KimberlitesFile)\n",
    "window = 10\n",
    "# Tmin = int(160)\n",
    "# Tmax = int(320)\n",
    "# Tmax = int(180)\n",
    "\n",
    "CalcOutputDir=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/s40rts/2867km/\"\n",
    "grid_dir=\"/Users/omer/Desktop/NatGeoReviews/Tomographic-Models/s40rts/\"\n",
    "OutputDirect=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/s40rts/2867km/\"\n",
    "TomogModelN=\"s40rts_2867\"\n",
    "\n",
    "\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)   \n",
    "\n",
    "\n",
    "recon_label = 'M21'\n",
    "ReconstructionDir='/Users/omer/Desktop/NatGeoReviews/Reconstruction_Models/M21/'\n",
    "cratonFile=ReconstructionDir+\"shapes_cratons_Merdith_et_al.gpml\"\n",
    "cratons = pygplates.FeatureCollection(cratonFile)    \n",
    "\n",
    "input_rotation_filename = '%s/1000_0_rotfile_Merdith_et_al.rot' % ReconstructionDir\n",
    "ANCHOR_ID = int(0)\n",
    "\n",
    "rotation_model=pygplates.RotationModel(input_rotation_filename)\n",
    "\n",
    "\n",
    "\n",
    "# fig2, ax2 = plt.subplots()\n",
    "nTests=1000\n",
    "\n",
    "for Age in np.arange(200,0,-20):\n",
    "    fig, ax = plt.subplots()\n",
    "    age = int(Age)\n",
    "    print(Age, 'Ma')\n",
    "    agemax = age+window\n",
    "    agemin = age-window\n",
    "\n",
    "    point_lats = []\n",
    "    point_lons = []\n",
    "    \n",
    "    MIN_DISTANCE_HOT_DEG=[]\n",
    "    MIN_SOLID_DISTANCE_DEG = []\n",
    "    MIN_DISTANCE_HOT_DEG = []\n",
    "    MIN_DISTANCE_HOT_DEG_STD = []\n",
    "\n",
    "#     DistancetoHot=\"%s/%s_Distance_to_Hot.nc\" %(CalcOutputDir,TomogModelN)\n",
    "    DistancetoHot=\"%s/%s_Distance_to_Hot_%s_AreaVaried.nc\" %(CalcOutputDir,TomogModelN,str(age))\n",
    "    print(DistancetoHot)\n",
    "    \n",
    "    point_lons, point_lats = get_volcanic_product_long_lat(rotation_model,ANCHOR_ID,age,window,pc)\n",
    "\n",
    "    pdist2hot = sample_using_gmt(DistancetoHot, point_lons, point_lats,CalcOutputDir)\n",
    "    \n",
    "    if len(pdist2hot) > 0:\n",
    "\n",
    "#         CUMULATIVE_MIN_DISTANCE_HOT_DEG.extend(pdist2hot)\n",
    "        MIN_DISTANCE_HOT_DEG=pdist2hot\n",
    "        MIN_DISTANCE_HOT_DEG_STD=np.std(pdist2hot)\n",
    "        \n",
    "#     print(CUMULATIVE_MIN_DISTANCE_HOT_DEG_STD)\n",
    "    \n",
    "    MEAN_MIN_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    MEDIAN_MIN_SOLID_DISTANCE_DEG = []\n",
    "\n",
    "    \n",
    "    \n",
    "    MEDIAN_MIN_SOLID_DISTANCE_DEG = np.median(np.array(MIN_DISTANCE_HOT_DEG),axis=0)\n",
    "\n",
    "\n",
    "    MEAN_MIN_SOLID_DISTANCE_DEG = np.mean(np.array(MIN_DISTANCE_HOT_DEG),axis=0)\n",
    "    print(MEAN_MIN_SOLID_DISTANCE_DEG,'is the mean of the sample')\n",
    "    \n",
    "    # Calculate how many points are on Hot Structures -->\n",
    "    k=np.asarray(MIN_DISTANCE_HOT_DEG)\n",
    "    k=np.where(k<0.01,0.0,k)\n",
    "    # np.where(np.asarray(CUMULATIVE_MIN_SOLID_DISTANCE_DEG) < 0.5)\n",
    "    NumberOfPointsOnCold=np.count_nonzero(np.asarray(k))\n",
    "    FractionOfPointsOnHotSOLIDCASE=100.0*(float(len(MIN_DISTANCE_HOT_DEG))-NumberOfPointsOnCold)/float(len(MIN_DISTANCE_HOT_DEG))\n",
    "    print(FractionOfPointsOnHotSOLIDCASE,'% of the points are on Hot Structures')\n",
    "    # --->\n",
    "    \n",
    "    \n",
    "    \n",
    "    #work out the random test\n",
    "    ALL_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "\n",
    "    MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    STD_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED =[]\n",
    "    \n",
    "    ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    \n",
    "    MEDIANS_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    \n",
    "    MEANS_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf=[]\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_5pc=[]\n",
    "    FRACTION_SMALLER_MEDIANS_ALL_MODELS_SOLID=[]\n",
    "    FRACTION_SMALLER_MEANS_ALL_MODELS_SOLID=[]\n",
    "    FRACTION_MEDIANS_AD_ALL_MODELS_SOLID=[]\n",
    "    FRACTION_MEANS_AD_ALL_MODELS_SOLID=[]\n",
    "    MEAN_MEDIANS_ALL_MODELS_SOLID=[]\n",
    "    MEDIAN_ALL_MODELS_SOLID=[]\n",
    "    MEDIAN_RANDOM_TEST_ALL_MODELS_SOLID=[]\n",
    "    CumulativeRand=[]\n",
    "\n",
    "    numKimbs=int(len(MIN_DISTANCE_HOT_DEG))\n",
    "    print(numKimbs)\n",
    "    KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided=[]\n",
    "    KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided=[]\n",
    "    \n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_stat_two_sided=[]\n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_pval_two_sided=[]\n",
    "    for m in range(nTests):\n",
    "        \n",
    "        if m % 10 == 0:\n",
    "            print('Random', m+1, 'out of', nTests)\n",
    "        \n",
    "        MIN_RANDOM_DISTANCE_TO_HOT = []\n",
    "        MIN_RANDOM_DISTANCE_TO_HOT_DEG = []\n",
    "        MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "        \n",
    "        random_pdist2hot = run_random_sampling(numKimbs,Age,DistancetoHot,CalcOutputDir)\n",
    "        \n",
    "        if len(random_pdist2hot) > 0:\n",
    "\n",
    "            MIN_RANDOM_DISTANCE_TO_HOT.extend(random_pdist2hot)\n",
    "\n",
    "        MIN_RANDOM_SOLID_DISTANCE_DEG = MIN_RANDOM_DISTANCE_TO_HOT\n",
    "        \n",
    "        \n",
    "        if(len(MIN_DISTANCE_HOT_DEG)==len(random_pdist2hot)):\n",
    "            ALL_MIN_RANDOM_SOLID_DISTANCE_DEG.append(MIN_RANDOM_DISTANCE_TO_HOT)        \n",
    "        else:\n",
    "            print('MUTATION!')\n",
    "#             random_pdist2hot = run_random_sampling(numKimbs,Age,DistancetoHot,CalcOutputDir)\n",
    "    \n",
    "            ALL_MIN_RANDOM_SOLID_DISTANCE_DEG=ALL_MIN_RANDOM_SOLID_DISTANCE_DEG\n",
    "\n",
    "        MEANS_ALL_RANDOM_SAMPLES_SOLID.append(np.mean(np.array(MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0))\n",
    "       \n",
    "        MEDIANS_ALL_RANDOM_SAMPLES_SOLID.append(np.median(np.array(MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0))\n",
    " \n",
    "        #plot the cumulative histogram\n",
    "        n, bins, patches = ax.hist(MIN_RANDOM_SOLID_DISTANCE_DEG, bins='fd', density=True, histtype='step',\n",
    "                                cumulative=True, color='grey', linewidth=0.2, zorder=1,alpha=0.20)\n",
    "\n",
    "        patches[0].set_xy(patches[0].get_xy()[:-1])\n",
    "        \n",
    "        \n",
    "       \n",
    "        AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG, \n",
    "                                                 MIN_RANDOM_SOLID_DISTANCE_DEG])\n",
    "        \n",
    "        \n",
    "        ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID.append(AD1S)\n",
    "        ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID.append(AD3S)\n",
    "#         print(AD3S, \"... confidence level\")\n",
    "        ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID.append(AD2S[2])\n",
    "    \n",
    "        KS1tS, KS2tS = stats.ks_2samp(MIN_DISTANCE_HOT_DEG, MIN_RANDOM_SOLID_DISTANCE_DEG,\n",
    "                                      alternative='two-sided', mode='exact')\n",
    "\n",
    "        KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided.append(KS1tS)\n",
    "        KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided.append(KS2tS)\n",
    "        \n",
    "    #work out the fraction of random tests for which the null hypothesis cannot be rejected,\n",
    "    #i.e. the sample distribution significantly differs from the random distribution\n",
    "    ADFS_conf=float(sum(i < 0.05 for i in ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))/float(len(ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))\n",
    "    \n",
    "    ADFS_conf_0_25=float(sum(i < 0.25 for i in ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))/float(len(ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))\n",
    "    print(ADFS_conf,ADFS_conf_0_25, \" are ADFS_conf and ADFS_conf_0_25\")\n",
    "\n",
    "    count_ADS=0\n",
    "    for k in range(len(ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID)):\n",
    "        if ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[k]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[k]:\n",
    "            count_ADS+=1\n",
    "    \n",
    "    ADFS_5pc=float(float(count_ADS)/float(len(ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID)))\n",
    "        \n",
    "\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf_25pc=[]\n",
    "    \n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf.append(ADFS_conf)\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_5pc.append(ADFS_5pc)\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf_25pc.append(ADFS_conf_0_25)\n",
    "    \n",
    "\n",
    "    p=0.05\n",
    "    \n",
    "    n=int(len(MIN_DISTANCE_HOT_DEG))\n",
    "    \n",
    "    if(n==19):\n",
    "        KScritNEW=0.1280\n",
    "        print(\"n=19\")\n",
    "    elif(n==12):\n",
    "        KScritNEW=0.1287\n",
    "        print(\"n=12\")\n",
    "    else:\n",
    "        KScritNEW=math.sqrt(-1.0*(math.log(1-p))/2.0) -(1.0/6.0)*n**(-1.0/2.0) +1/n\n",
    "        print(\"n>30\")\n",
    "   \n",
    "    KSFS_stat_two_sided=float(sum(i > KScritNEW for i in KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided))/float(len(KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided))\n",
    "\n",
    "    KSFS_pval_two_sided=float(sum(i < 0.05 for i in KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided))/float(len(KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided))\n",
    "    \n",
    "    countSmean_KS=0\n",
    "    for l in range(nTests):\n",
    "        \n",
    "        #find the number of successful tests for the solid case\n",
    "#         if KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided[l] < KScritNEW \\\n",
    "#         or KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided[l] > 0.05:\n",
    "#             countSmean_KS+=1\n",
    "        \n",
    "        if (KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided[l] < KScritNEW):\n",
    "            countSmean_KS+=1\n",
    "        \n",
    "    FRACTION_KS_Crit=float(1.0- countSmean_KS/nTests)\n",
    "    \n",
    "    countSmean_KS=0\n",
    "    for l in range(nTests):\n",
    "        \n",
    "        if KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided[l] < KScritNEW \\\n",
    "        or KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided[l] > 0.05:\n",
    "            countSmean_KS+=1\n",
    "     \n",
    "    FRACTION_KS_Crit_TwoCond=float(1.0- countSmean_KS/nTests)        \n",
    "    \n",
    "   #\n",
    "#     ADFS_conf=float(sum(i < 0.05 for i in ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))/float(len(ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))\n",
    "    \n",
    "#     count_ADS=0\n",
    "#     for k in range(len(ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID)):\n",
    "#         if ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[k]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[k]:\n",
    "#             count_ADS+=1\n",
    "    \n",
    "#     ADFS_5pc=float(float(count_ADS)/float(len(ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID)))\n",
    "    \n",
    "#     FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf.append(ADFS_conf)\n",
    "#     FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_5pc.append(ADFS_5pc)\n",
    "    \n",
    "    \n",
    "    #work out the fraction of random tests for which the median distance is greater than\n",
    "    #in the sample distribution, i.e. sample points are closer to basal structures than\n",
    "    #random points\n",
    "    \n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_stat_two_sided.append(KSFS_stat_two_sided)\n",
    "    \n",
    "    \n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_pval_two_sided.append(KSFS_pval_two_sided)\n",
    "\n",
    "\n",
    "    \n",
    "    #work out the fraction of random tests for which the median distance is greater than\n",
    "    #in the sample distribution, i.e. sample points are closer to basal structures than\n",
    "    #random points\n",
    "    \n",
    "    FRACTION_SMALLER_MEDIANS_SOLID=float(sum(abs(i) > abs(MEDIAN_MIN_SOLID_DISTANCE_DEG) for i in MEDIANS_ALL_RANDOM_SAMPLES_SOLID))/float(len(MEDIANS_ALL_RANDOM_SAMPLES_SOLID))\n",
    "   \n",
    "    FRACTION_SMALLER_MEDIANS_ALL_MODELS_SOLID.append(FRACTION_SMALLER_MEDIANS_SOLID)\n",
    "   \n",
    "    FRACTION_SMALLER_MEANS_SOLID = float(sum(i > MEAN_MIN_SOLID_DISTANCE_DEG for i in MEANS_ALL_RANDOM_SAMPLES_SOLID))/float(len(MEANS_ALL_RANDOM_SAMPLES_SOLID))\n",
    "   \n",
    "    FRACTION_SMALLER_MEANS_ALL_MODELS_SOLID.append(FRACTION_SMALLER_MEANS_SOLID)\n",
    "    \n",
    "    \n",
    "    countSmean=0 # \n",
    "#     countEmean=0\n",
    "    countSmedian=0\n",
    "    countSmeanWeak=0\n",
    "#     countEmedian=0\n",
    "    for l in range(nTests):\n",
    "        if MEANS_ALL_RANDOM_SAMPLES_SOLID[l] >= MEAN_MIN_SOLID_DISTANCE_DEG \\\n",
    "        and ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[l]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[l]:\n",
    "            countSmean+=1\n",
    "            \n",
    "        if ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[l]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[l]:\n",
    "            countSmeanWeak+=1    \n",
    "                \n",
    "        if abs(MEDIANS_ALL_RANDOM_SAMPLES_SOLID[l]) >= abs(MEDIAN_MIN_SOLID_DISTANCE_DEG) \\\n",
    "        and ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[l]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[l]:\n",
    "            countSmedian+=1\n",
    "            \n",
    "    FRACTION_MEANS_AD_SOLID=float(float(countSmean)/float(nTests))\n",
    "    FRACTION_MEANS_AD_SOLIDWeak=float(float(countSmeanWeak)/float(nTests))\n",
    "    FRACTION_MEANS_AD_ALL_MODELS_SOLID.append(FRACTION_MEANS_AD_SOLID)\n",
    "\n",
    "    FRACTION_MEDIANS_AD_SOLID=float(float(countSmedian)/float(nTests))\n",
    "    FRACTION_MEDIANS_AD_ALL_MODELS_SOLID.append(FRACTION_MEDIANS_AD_SOLID)\n",
    "    \n",
    "#     print((100.0*float(countSmean)/nTests),' % of the time mean of the sample is less than random-Solid and Significantly Differs From Random')\n",
    "    \n",
    "    MEAN_MEDIANS_ALL_MODELS_SOLID.append(np.mean(np.array(MEDIANS_ALL_RANDOM_SAMPLES_SOLID),axis=0))\n",
    "    \n",
    "    #work out mean and median for the average of random samples for the solid case\n",
    "    MEAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    MEDIAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED=np.sort(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG, axis=-1,kind='stable')\n",
    "    MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.mean(np.array(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED),axis=0)\n",
    "\n",
    "#     below are the actual mim-max range\n",
    "    MIN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.amin(np.array(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED), axis=0)\n",
    "    MAX_MIN_RANDOM_SOLID_DISTANCE_DEG = np.amax(np.array(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED), axis=0)\n",
    "    \n",
    "    MEAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.mean(np.array(MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0)\n",
    "    MEDIAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.median(np.array(MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0)\n",
    "            \n",
    "    MEDIAN_ALL_MODELS_SOLID.append(MEDIAN_MIN_SOLID_DISTANCE_DEG)\n",
    "    MEDIAN_RANDOM_TEST_ALL_MODELS_SOLID.append(MEDIAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n6, bins6, patches6 = ax.hist(MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG, bins='fd', density=True, histtype='step',\n",
    "                            cumulative=True, label='Mean-Random', color='black', linewidth=3, zorder=4)\n",
    "    \n",
    "    patches6[0].set_xy(patches6[0].get_xy()[:-1])\n",
    "\n",
    "    \n",
    "    #plot the cumulative histogram\n",
    "#     a=np.asarray(MIN_SOLID_DISTANCE_DEG)\n",
    "    a=np.asarray(MIN_DISTANCE_HOT_DEG)\n",
    "    a=a.round(4)\n",
    "    \n",
    "    n7, bins7, patches7 = ax.hist(a, bins='fd', density=True, histtype='step',\n",
    "                            cumulative=True, label='s40rts-2867km', color='red', linewidth=3, zorder=5)\n",
    "        \n",
    "    patches7[0].set_xy(patches7[0].get_xy()[:-1])\n",
    "    \n",
    "    # tidy up the figure\n",
    "\n",
    "    #ax.grid(True)\n",
    "#     ax.grid()\n",
    "    ax.grid(zorder=0,linestyle='--', color='lightgrey')\n",
    "#     ax.legend(loc='lower right')\n",
    "    ax.set_xlim(0,20)\n",
    "    #ax.set_title('Cumulative step histograms')\n",
    "    ax.set_xlabel('Minimum angular distance ($\\degree$)')\n",
    "    ax.set_ylabel('Cumulative probability')\n",
    "#     ax.set_title('{:s} (Solid)'.format(model_case))\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "        r'Age= %i Ma' %(Age,),\n",
    "        r'n=%i' %(numKimbs,),\n",
    "        r'$\\overline{\\theta}_{Sample}=%.2f\\degree$' % (MEAN_MIN_SOLID_DISTANCE_DEG, ),\n",
    "        r'$\\overline{\\theta}_{Random}=%.2f\\degree$' %(np.mean(MEANS_ALL_RANDOM_SAMPLES_SOLID), ),\n",
    "        r'$f_{K-S}=%.2f$' %(FRACTION_KS_Crit), # based on critical val.\n",
    "        r'$f_{A-D}=%.2f$' %(ADFS_conf))) # 5 percent sig.\n",
    "\n",
    "\n",
    "#         r'${\\kappa}_{\\bar{\\theta}}=%.2f$' % (FRACTION_SMALLER_MEANS_SOLID, )))\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.80,edgecolor='lightgrey')\n",
    "    #ax.grid(True)\n",
    "#     ax.grid(zorder=0,linestyle='--', color='lightgrey')\n",
    "    # Create new legend handles but use the colors from the existing ones\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = [Line2D([], [], c=h.get_edgecolor()) for h in handles]\n",
    "    ax.legend(handles=new_handles[::-1], labels=labels[::-1], loc='lower left')\n",
    "    ax.text(0.65, 0.10, textstr, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='bottom', bbox=props)\n",
    " \n",
    "    ax.grid(zorder=1,linestyle='--', color='lightgrey')\n",
    "    \n",
    "    fig.savefig('/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/s40rts/2867km/s40rts-2867-km-'+str(Age)+'-Ma_AreaVaried.pdf', \n",
    "                bbox_inches='tight', dpi=600)\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    OutputDir=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/s40rts/Saved-Arrays\"\n",
    "    \n",
    "    np.savetxt(OutputDir+'/s40rts-2867km-MIN-DISTANCES_'+str(Age)+'_Ma_AreaVaried.txt',MIN_DISTANCE_HOT_DEG)\n",
    "\n",
    "    np.save(OutputDir+'/s40rts-2867km-MIN-DISTANCES-STD_'+str(Age)+'_Ma_AreaVaried.npy',MIN_DISTANCE_HOT_DEG_STD)\n",
    "\n",
    "    np.save(OutputDir+'/s40rts-2867km-AD-Test-conf-5p-'+str(Age)+'_Ma_AreaVaried.npy',ADFS_conf)\n",
    "\n",
    "    np.save(OutputDir+'/s40rts-2867km-AD-Test-conf-25p-'+str(Age)+'_Ma_AreaVaried.npy',ADFS_conf_0_25)\n",
    "\n",
    "    np.save(OutputDir+'/s40rts-2867km-ks-stat-two-sided-'+str(Age)+'_Ma_AreaVaried.npy',KSFS_stat_two_sided)\n",
    "    \n",
    "    np.save(OutputDir+'/s40rts-2867km-ks-stat-pval-'+str(Age)+'_Ma_AreaVaried.npy',KSFS_pval_two_sided)\n",
    "   \n",
    "    np.save(OutputDir+'/s40rts-2867km-ks-stat-TwoCond-'+str(Age)+'_Ma_AreaVaried.npy',FRACTION_KS_Crit_TwoCond)\n",
    "    \n",
    "    np.save(OutputDir+'/s40rts-2867km-KS-Stat-critical-val'+str(Age)+'_Ma_AreaVaried.npy',FRACTION_KS_Crit)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(MIN_DISTANCE_HOT_DEG),len(random_pdist2hot)\n",
    "#             ALL_MIN_RANDOM_SOLID_DISTANCE_DEG.append(MIN_RANDOM_DISTANCE_TO_HOT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_pdist2hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRACTION_MEANS_AD_SOLID is the % that shorter distance and highly difference from random is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRACTION_MEANS_AD_SOLID,FRACTION_MEANS_AD_SOLIDWeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
