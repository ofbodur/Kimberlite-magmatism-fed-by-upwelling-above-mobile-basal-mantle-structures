{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'C:/Users/annal/OneDrive/Documents/python3.8/pygplates_rev28_python38_win64')\n",
    "# sys.path.insert(0,'/Users/omer/Documents/pygplates_rev18_python27_MacOS64')\n",
    "sys.path.insert(0,'/Users/omer/Documents/pygplates_rev28_python38_MacOS64/')\n",
    "sys.path.insert(1,'/Applications/GMT-6.0.0.app/Contents/Resources')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install healpy \n",
    "# !pip instadll statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygplates\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import sphere_tools as sph\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import sys\n",
    "from matplotlib.lines import Line2D\n",
    "from call_system_command import call_system_command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_number_of_LIPs(age,window,point_features):\n",
    "    \n",
    "    agemax = age+window\n",
    "    agemin = age-window\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for p in point_features:\n",
    "        \n",
    "        # NB valid_time is a tuple, we take the first value since this is the 'birth' time of the LIP\n",
    "        BirthTime = p.get_valid_time()[0] \n",
    "        \n",
    "        if BirthTime <= agemax and BirthTime > agemin:\n",
    "            \n",
    "            count+=1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volcanic_product_long_lat(rotations,anchor_plate_id,age,window,point_features):\n",
    "    \n",
    "    agemax = age+window\n",
    "    agemin = age-window\n",
    "    \n",
    "    Xr = []\n",
    "    Yr = []\n",
    "\n",
    "    for p in point_features:\n",
    "        \n",
    "        # NB valid_time is a tuple, we take the first value since this is the 'birth' time of the Kimberlite\n",
    "        BirthTime = p.get_valid_time()[0] \n",
    "        \n",
    "        if BirthTime <= agemax and BirthTime > agemin:\n",
    "            \n",
    "            PlateID = p.get_reconstruction_plate_id()\n",
    "\n",
    "            # Get rotation for the point and reconstruct to its birth time if it's in age interval (window)\n",
    "            Kimb_rotation = rotations.get_rotation(age, PlateID, anchor_plate_id)\n",
    "\n",
    "            reconstructed_point = Kimb_rotation * p.get_geometry()\n",
    "            reconstructed_point_degrees = reconstructed_point.to_lat_lon_point()\n",
    "\n",
    "            Xr.append(reconstructed_point_degrees.get_longitude())\n",
    "            Yr.append(reconstructed_point_degrees.get_latitude())\n",
    "    \n",
    "    \n",
    "    return Xr, Yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function to sample grids using grdtrack and read results\n",
    "def sample_using_gmt(grdfile, point_lons, point_lats,OutputDirectory):\n",
    "\n",
    "        dataout = np.vstack((np.asarray(point_lons),np.asarray(point_lats))).T\n",
    "\n",
    "        np.savetxt(OutputDirectory+'/tmp.txt',dataout)\n",
    "        \n",
    "        # Note -nn forces nearest neighbour interpolation\n",
    "        call_system_command(['gmt',\n",
    "                             'grdtrack',\n",
    "                             '%s/tmp.txt' %OutputDirectory,\n",
    "                             '-G{:s}'.format(grdfile), \n",
    "                             '-fg',\n",
    "                             '-nn',\n",
    "                             '-V',\n",
    "                             '>', \n",
    "                             '%s/tmp_interp.txt' % OutputDirectory])\n",
    "        G=[]\n",
    "        with open(OutputDirectory+'/tmp_interp.txt') as f:\n",
    "            for line in f:\n",
    "                if line[0] == '>':\n",
    "                    continue\n",
    "                else:\n",
    "                    tmp = line.split()\n",
    "                    G.append(float(tmp[2]))\n",
    "\n",
    "        f.close()\n",
    "        return np.array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_hot_nc_file(GridDirect,OutputDirect,TomogModelName,percentContourValue):\n",
    "    \n",
    "    GridFile=\"%s/%s.nc\" %(GridDirect,TomogModelName)\n",
    "    ContourFile=\"%s/%s_Contour.txt\" %(OutputDirect,TomogModelName)\n",
    "    TempGrid1=\"%s/%s_TempGrid1.nc\" %(OutputDirect,TomogModelName)\n",
    "    TempGrid2=\"%s/%s_TempGrid2.nc\" %(OutputDirect,TomogModelName)\n",
    "    hot_xyz_file=\"%s/%s_hot.xyz\" %(OutputDirect,TomogModelName)\n",
    "    \n",
    "    DistanceFROMHot=\"%s/%s_Distance_to_Hot.nc\" %(OutputDirect,TomogModelName)\n",
    "    \n",
    "    \n",
    "    percentContourValueHigh=percentContourValue*(1.0-0.01)\n",
    "    percentContourValueLow=percentContourValue*(1.0+0.01)\n",
    "   \n",
    "    call_system_command(['gmt',\n",
    "                     'grdcontour',\n",
    "                     GridFile,\n",
    "                     '-D%s' % ContourFile,\n",
    "                     '-C1',\n",
    "                     '-L/-0.303/-0.297'])\n",
    "#                      '-L%.1f/%.1f',(percentContourValueLow,percentContourValueHigh)])\n",
    "    \n",
    "    call_system_command(['gmt',\n",
    "                      'grdclip',\n",
    "                     GridFile,\n",
    "                     '-Rd',\n",
    "                     '-Sa%.1f/1' % percentContourValue,\n",
    "                     '-G%s' % TempGrid1])\n",
    "    \n",
    "    call_system_command(['gmt',\n",
    "                      'grdclip',\n",
    "                     TempGrid1,\n",
    "                     '-Rd',\n",
    "                     '-Sb1/0',\n",
    "                     '-G%s' % TempGrid2])\n",
    "    \n",
    "    \n",
    "    call_system_command(['gmt',\n",
    "                         'grd2xyz',\n",
    "                         TempGrid2,\n",
    "                         '-Rd',\n",
    "                         '-di1',  # set all cells with '1' to be nodata\n",
    "                         '-s',\n",
    "                         '>',\n",
    "                         '%s' % hot_xyz_file])\n",
    "\n",
    "    call_system_command(['gmt',\n",
    "                         'grdmath',\n",
    "                         TempGrid2,\n",
    "                         '%s' % hot_xyz_file,\n",
    "                         'PDIST',\n",
    "                         'KM2DEG',\n",
    "                         '=',\n",
    "                         '%s' % DistanceFROMHot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridDirect=\"/Users/omer/Desktop/NatGeoReviews/Tomographic-Models/SEMUCB-WM1/\"\n",
    "OutputDirect=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/SEMUCB-WM1/2867km/\"\n",
    "TomogModel=\"SEMUCB-WM1_2867\"\n",
    "\n",
    "# \"%s%s.nc\" %(GridDirect,TomogModel)\n",
    "# create_hot_nc_file(GridDirect,OutputDirect,TomogModel,-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistanceFROMHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_sampling(nPoints,age,dist_to_hot_nc_file,CalcOutputDir):\n",
    "    \n",
    "#     recon_label = '2017NNR'\n",
    "\n",
    "#     basedir='/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/M21NNR/NNR/NNR_InFiles/'\n",
    "#     input_rotation_filename1 = '%s/1000-410_rotations-NNR.rot' % basedir\n",
    "#     input_rotation_filename2 = '%s/Global_EB_410-250Ma_GK07_2017-NNR.rot' % basedir\n",
    "#     input_rotation_filename3 = '%s/Global_EB_250-0Ma_GK07_2017-NNR.rot' % basedir\n",
    "#     input_rotation_filename4 = '%s/NR_0Ma_1000Ma_for_gplates.rot' % basedir\n",
    "#     rotation_model = pygplates.RotationModel([input_rotation_filename1,input_rotation_filename2,\\\n",
    "#                                               input_rotation_filename3,input_rotation_filename4])\n",
    "\n",
    "#     ANCHOR_ID = int(0)\n",
    "#     cratonFileDir='/Users/omer/Documents/Programming/PyGplates/Supplement/Reconstructions/M21NNR/'\n",
    "#     cratonFile=cratonFileDir+\"shapes_cratons_Merdith_et_al.gpml\"\n",
    "    \n",
    "#     cratonFileDir='/Users/omer/Documents/Programming/PyGplates/Supplement/Reconstructions/NewCratonsForAnalysis/'\n",
    "#     cratonFile=cratonFileDir+\"cratons_150km_thick_with_plate_IDs_manually_edited.gpml\"\n",
    "    age=int(age)\n",
    "    recon_label = 'M21'\n",
    "    ReconstructionDir='/Users/omer/Desktop/NatGeoReviews/Reconstruction_Models/M21/'\n",
    "    cratonFile=ReconstructionDir+\"shapes_cratons_Merdith_et_al.gpml\"\n",
    "    cratons = pygplates.FeatureCollection(cratonFile)    \n",
    "\n",
    "    input_rotation_filename = '%s/1000_0_rotfile_Merdith_et_al.rot' % ReconstructionDir\n",
    "    ANCHOR_ID = int(0)\n",
    "    \n",
    "    rotation_model=pygplates.RotationModel(input_rotation_filename)\n",
    "\n",
    "    randomLons = []\n",
    "    randomLats = []\n",
    "    random_pdist2hot = []\n",
    "   \n",
    "    \n",
    "    # Start with an empty list of features\n",
    "    features_to_modify = []\n",
    "    new_features=[]\n",
    "    reconstructed_feature_geometries=[]\n",
    "    \n",
    "    # Reconstruct cratonic shapes at Age Ma\n",
    "    pygplates.reconstruct(cratons, rotation_model, reconstructed_feature_geometries, age)\n",
    "    \n",
    "#     print(reconstructed_feature_geometries)\n",
    "#     print(age)\n",
    "    \n",
    "    RandomPoints_Lats=np.array([])\n",
    "    RandomPoints_Lons=np.array([])\n",
    "    \n",
    "    totalRandomInsideCratons=0\n",
    "    \n",
    "    while(totalRandomInsideCratons<nPoints):\n",
    "        random_point = sph.random_points_feature(1)\n",
    "        for mp in random_point:\n",
    "            for point in mp.get_geometry().get_points():\n",
    "                pointInDegrees=point.to_lat_lon_point()\n",
    "                PointLat=pointInDegrees.get_latitude()\n",
    "                PointLon=pointInDegrees.get_longitude()\n",
    "                \n",
    "#                 for static_polygon in cratons:\n",
    "                for static_polygon in reconstructed_feature_geometries:\n",
    "#                     PlateID = static_polygon.get_reconstruction_plate_id()\n",
    "#                     static_polygon_geom = static_polygon.get_geometry()\n",
    "                    static_polygon_geom = static_polygon.get_reconstructed_geometry()\n",
    "                    if static_polygon_geom != None:\n",
    "                        if static_polygon_geom.is_point_in_polygon((PointLat,PointLon)):        \n",
    "#                             print(\"inside\")\n",
    "                            RandomPoints_Lats=np.append(RandomPoints_Lats,PointLat)\n",
    "                            RandomPoints_Lons=np.append(RandomPoints_Lons,PointLon)\n",
    "                            totalRandomInsideCratons=totalRandomInsideCratons+1\n",
    "                            cF=pygplates.Feature()\n",
    "                            cF.set_geometry(point)\n",
    "                            new_features.append(cF)\n",
    "    output_feature_collection = pygplates.FeatureCollection(new_features)\n",
    "    output_feature_collection.write(\"Random_\"+str(nPoints)+\"_Points_onCratons_ForSEMUCB-WM1_\"+str(age)+\"_Ma.gpml\")\n",
    "\n",
    "    # for the point locations of interest, sample the distance grids\n",
    "    # (and the original cluster boolean grid as a sanity check)\n",
    "    random_pdist2hot = sample_using_gmt(dist_to_hot_nc_file, RandomPoints_Lons, RandomPoints_Lats,CalcOutputDir)\n",
    "#     random_cluster_bool = sample_using_gmt(cluster_nc_file, RandomPoints_Lons, RandomPoints_Lats)\n",
    "    \n",
    "    return random_pdist2hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_feature_geometries=[]\n",
    "# pygplates.reconstruct(cratons, rotation_model, reconstructed_feature_geometries, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_feature_geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 Ma\n",
      "34\n",
      "1.104413467294706 is the mean of the sample\n",
      "55.88235294117647 % of the points are on Hot Structures\n",
      "34\n",
      "Random 1 out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c796587ca98f>:161: UserWarning: p-value capped: true value larger than 0.25\n",
      "  AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG,\n",
      "<ipython-input-15-c796587ca98f>:161: UserWarning: p-value capped: true value larger than 0.25\n",
      "  AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG,\n",
      "<ipython-input-15-c796587ca98f>:161: UserWarning: p-value capped: true value larger than 0.25\n",
      "  AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG,\n",
      "<ipython-input-15-c796587ca98f>:161: UserWarning: p-value capped: true value larger than 0.25\n",
      "  AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG,\n",
      "<ipython-input-15-c796587ca98f>:161: UserWarning: p-value capped: true value larger than 0.25\n",
      "  AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c796587ca98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mrandom_pdist2hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_random_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumKimbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDistancetoHot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCalcOutputDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_pdist2hot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-f65e489b28b7>\u001b[0m in \u001b[0;36mrun_random_sampling\u001b[0;34m(nPoints, age, dist_to_hot_nc_file, CalcOutputDir)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalRandomInsideCratons\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mnPoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mrandom_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_points_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mpointInDegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_lat_lon_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# root_dir = '/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/'\n",
    "# grid_dir = '/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/'\n",
    "# solid_plot_dir = '/Users/omer/Documents/Programming/PyGplates/Supplement/Latest/solid'\n",
    "KimberlitesFile='/Users/omer/Desktop/NatGeoReviews/Kimberlites/Tappe-et-al-2018-EPSL-Kimberlite_emplacement_ages-automatic-part1-with-locations-with-plate-IDs.gpml'\n",
    "pc = pygplates.FeatureCollection(KimberlitesFile)\n",
    "window = 10\n",
    "# Tmin = int(160)\n",
    "# Tmax = int(320)\n",
    "# Tmax = int(180)\n",
    "\n",
    "CalcOutputDir=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/SEMUCB-WM1/2867km/\"\n",
    "grid_dir=\"/Users/omer/Desktop/NatGeoReviews/Tomographic-Models/SEMUCB-WM1/\"\n",
    "OutputDirect=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/SEMUCB-WM1/2867km/\"\n",
    "TomogModelN=\"SEMUCB-WM1_2867\"\n",
    "\n",
    "\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)   \n",
    "\n",
    "\n",
    "recon_label = 'M21'\n",
    "ReconstructionDir='/Users/omer/Desktop/NatGeoReviews/Reconstruction_Models/M21/'\n",
    "cratonFile=ReconstructionDir+\"shapes_cratons_Merdith_et_al.gpml\"\n",
    "cratons = pygplates.FeatureCollection(cratonFile)    \n",
    "\n",
    "input_rotation_filename = '%s/1000_0_rotfile_Merdith_et_al.rot' % ReconstructionDir\n",
    "ANCHOR_ID = int(0)\n",
    "\n",
    "rotation_model=pygplates.RotationModel(input_rotation_filename)\n",
    "\n",
    "\n",
    "\n",
    "# fig2, ax2 = plt.subplots()\n",
    "nTests=1000\n",
    "\n",
    "for Age in np.arange(180,160,-20):\n",
    "    fig, ax = plt.subplots()\n",
    "    age = int(Age)\n",
    "    print(Age, 'Ma')\n",
    "    agemax = age+window\n",
    "    agemin = age-window\n",
    "\n",
    "    point_lats = []\n",
    "    point_lons = []\n",
    "    \n",
    "    MIN_DISTANCE_HOT_DEG=[]\n",
    "    MIN_SOLID_DISTANCE_DEG = []\n",
    "    MIN_DISTANCE_HOT_DEG = []\n",
    "    MIN_DISTANCE_HOT_DEG_STD = []\n",
    "\n",
    "    DistancetoHot=\"%s/%s_Distance_to_Hot.nc\" %(CalcOutputDir,TomogModelN)\n",
    "        \n",
    "    point_lons, point_lats = get_volcanic_product_long_lat(rotation_model,ANCHOR_ID,age,window,pc)\n",
    "    print(len(point_lons))\n",
    "    pdist2hot = sample_using_gmt(DistancetoHot, point_lons, point_lats,CalcOutputDir)\n",
    "    \n",
    "    if len(pdist2hot) > 0:\n",
    "\n",
    "#         CUMULATIVE_MIN_DISTANCE_HOT_DEG.extend(pdist2hot)\n",
    "        MIN_DISTANCE_HOT_DEG=pdist2hot\n",
    "        MIN_DISTANCE_HOT_DEG_STD=np.std(pdist2hot)\n",
    "        \n",
    "#     print(CUMULATIVE_MIN_DISTANCE_HOT_DEG_STD)\n",
    "    \n",
    "    MEAN_MIN_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    MEDIAN_MIN_SOLID_DISTANCE_DEG = []\n",
    "\n",
    "    \n",
    "    \n",
    "    MEDIAN_MIN_SOLID_DISTANCE_DEG = np.median(np.array(MIN_DISTANCE_HOT_DEG),axis=0)\n",
    "\n",
    "\n",
    "    MEAN_MIN_SOLID_DISTANCE_DEG = np.mean(np.array(MIN_DISTANCE_HOT_DEG),axis=0)\n",
    "    print(MEAN_MIN_SOLID_DISTANCE_DEG,'is the mean of the sample')\n",
    "    \n",
    "    # Calculate how many points are on Hot Structures -->\n",
    "    k=np.asarray(MIN_DISTANCE_HOT_DEG)\n",
    "    k=np.where(k<0.01,0.0,k)\n",
    "    # np.where(np.asarray(CUMULATIVE_MIN_SOLID_DISTANCE_DEG) < 0.5)\n",
    "    NumberOfPointsOnCold=np.count_nonzero(np.asarray(k))\n",
    "    FractionOfPointsOnHotSOLIDCASE=100.0*(float(len(MIN_DISTANCE_HOT_DEG))-NumberOfPointsOnCold)/float(len(MIN_DISTANCE_HOT_DEG))\n",
    "    print(FractionOfPointsOnHotSOLIDCASE,'% of the points are on Hot Structures')\n",
    "    # --->\n",
    "    \n",
    "    \n",
    "    \n",
    "    #work out the random test\n",
    "    ALL_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "\n",
    "    MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    STD_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED =[]\n",
    "    \n",
    "    ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    \n",
    "    MEDIANS_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    \n",
    "    MEANS_ALL_RANDOM_SAMPLES_SOLID = []\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf=[]\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_5pc=[]\n",
    "    FRACTION_SMALLER_MEDIANS_ALL_MODELS_SOLID=[]\n",
    "    FRACTION_SMALLER_MEANS_ALL_MODELS_SOLID=[]\n",
    "    FRACTION_MEDIANS_AD_ALL_MODELS_SOLID=[]\n",
    "    FRACTION_MEANS_AD_ALL_MODELS_SOLID=[]\n",
    "    MEAN_MEDIANS_ALL_MODELS_SOLID=[]\n",
    "    MEDIAN_ALL_MODELS_SOLID=[]\n",
    "    MEDIAN_RANDOM_TEST_ALL_MODELS_SOLID=[]\n",
    "    CumulativeRand=[]\n",
    "\n",
    "    numKimbs=int(len(MIN_DISTANCE_HOT_DEG))\n",
    "    print(numKimbs)\n",
    "    KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided=[]\n",
    "    KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided=[]\n",
    "    \n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_stat_two_sided=[]\n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_pval_two_sided=[]\n",
    "    for m in range(nTests):\n",
    "        \n",
    "        if m % 10 == 0:\n",
    "            print('Random', m+1, 'out of', nTests)\n",
    "        \n",
    "        MIN_RANDOM_DISTANCE_TO_HOT = []\n",
    "        MIN_RANDOM_DISTANCE_TO_HOT_DEG = []\n",
    "        MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "        \n",
    "        random_pdist2hot = run_random_sampling(numKimbs,Age,DistancetoHot,CalcOutputDir)\n",
    "        \n",
    "        if len(random_pdist2hot) > 0:\n",
    "\n",
    "            MIN_RANDOM_DISTANCE_TO_HOT.extend(random_pdist2hot)\n",
    "\n",
    "        MIN_RANDOM_SOLID_DISTANCE_DEG = MIN_RANDOM_DISTANCE_TO_HOT\n",
    "        \n",
    "        \n",
    "        if(len(MIN_DISTANCE_HOT_DEG)==len(random_pdist2hot)):\n",
    "            ALL_MIN_RANDOM_SOLID_DISTANCE_DEG.append(MIN_RANDOM_DISTANCE_TO_HOT)        \n",
    "        else:\n",
    "            print('MUTATION!')\n",
    "#             random_pdist2hot = run_random_sampling(numKimbs,Age,DistancetoHot,CalcOutputDir)\n",
    "    \n",
    "            ALL_MIN_RANDOM_SOLID_DISTANCE_DEG=ALL_MIN_RANDOM_SOLID_DISTANCE_DEG\n",
    "\n",
    "        MEANS_ALL_RANDOM_SAMPLES_SOLID.append(np.mean(np.array(MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0))\n",
    "       \n",
    "        MEDIANS_ALL_RANDOM_SAMPLES_SOLID.append(np.median(np.array(MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0))\n",
    " \n",
    "        #plot the cumulative histogram\n",
    "        n, bins, patches = ax.hist(MIN_RANDOM_SOLID_DISTANCE_DEG, bins='fd', density=True, histtype='step',\n",
    "                                cumulative=True, color='grey', linewidth=0.2, zorder=1,alpha=0.20)\n",
    "\n",
    "        patches[0].set_xy(patches[0].get_xy()[:-1])\n",
    "        \n",
    "        \n",
    "       \n",
    "        AD1S, AD2S, AD3S = stats.anderson_ksamp([MIN_DISTANCE_HOT_DEG, \n",
    "                                                 MIN_RANDOM_SOLID_DISTANCE_DEG])\n",
    "        \n",
    "        \n",
    "        ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID.append(AD1S)\n",
    "        ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID.append(AD3S)\n",
    "#         print(AD3S, \"... confidence level\")\n",
    "        ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID.append(AD2S[2])\n",
    "    \n",
    "        KS1tS, KS2tS = stats.ks_2samp(MIN_DISTANCE_HOT_DEG, MIN_RANDOM_SOLID_DISTANCE_DEG,\n",
    "                                      alternative='two-sided', mode='exact')\n",
    "\n",
    "        KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided.append(KS1tS)\n",
    "        KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided.append(KS2tS)\n",
    "        \n",
    "    #work out the fraction of random tests for which the null hypothesis cannot be rejected,\n",
    "    #i.e. the sample distribution significantly differs from the random distribution\n",
    "    ADFS_conf=float(sum(i < 0.05 for i in ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))/float(len(ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))\n",
    "    \n",
    "    ADFS_conf_0_25=float(sum(i < 0.25 for i in ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))/float(len(ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))\n",
    "    print(ADFS_conf,ADFS_conf_0_25, \" are ADFS_conf and ADFS_conf_0_25\")\n",
    "\n",
    "    count_ADS=0\n",
    "    for k in range(len(ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID)):\n",
    "        if ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[k]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[k]:\n",
    "            count_ADS+=1\n",
    "    \n",
    "    ADFS_5pc=float(float(count_ADS)/float(len(ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID)))\n",
    "        \n",
    "\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf_25pc=[]\n",
    "    \n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf.append(ADFS_conf)\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_5pc.append(ADFS_5pc)\n",
    "    FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf_25pc.append(ADFS_conf_0_25)\n",
    "    \n",
    "\n",
    "    p=0.05\n",
    "    \n",
    "    n=int(len(MIN_DISTANCE_HOT_DEG))\n",
    "    \n",
    "    if(n==19):\n",
    "        KScritNEW=0.1280\n",
    "        print(\"n=19\")\n",
    "    elif(n==12):\n",
    "        KScritNEW=0.1287\n",
    "        print(\"n=12\")\n",
    "    else:\n",
    "        KScritNEW=math.sqrt(-1.0*(math.log(1-p))/2.0) -(1.0/6.0)*n**(-1.0/2.0) +1/n\n",
    "        print(\"n>30\")\n",
    "   \n",
    "    KSFS_stat_two_sided=float(sum(i > KScritNEW for i in KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided))/float(len(KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided))\n",
    "\n",
    "    KSFS_pval_two_sided=float(sum(i < 0.05 for i in KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided))/float(len(KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided))\n",
    "    \n",
    "    countSmean_KS=0\n",
    "    for l in range(nTests):\n",
    "        \n",
    "        #find the number of successful tests for the solid case\n",
    "#         if KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided[l] < KScritNEW \\\n",
    "#         or KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided[l] > 0.05:\n",
    "#             countSmean_KS+=1\n",
    "        \n",
    "        if (KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided[l] < KScritNEW):\n",
    "            countSmean_KS+=1\n",
    "        \n",
    "    FRACTION_KS_Crit=float(1.0- countSmean_KS/nTests)\n",
    "    \n",
    "    countSmean_KS=0\n",
    "    for l in range(nTests):\n",
    "        \n",
    "        if KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_stat_two_sided[l] < KScritNEW \\\n",
    "        or KOLMOGOROV_ALL_RANDOM_SAMPLES_SOLID_pval_two_sided[l] > 0.05:\n",
    "            countSmean_KS+=1\n",
    "     \n",
    "    FRACTION_KS_Crit_TwoCond=float(1.0- countSmean_KS/nTests)        \n",
    "    \n",
    "   #\n",
    "#     ADFS_conf=float(sum(i < 0.05 for i in ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))/float(len(ANDERSON_DARLING_CONFIDENCE_ALL_RANDOM_SAMPLES_SOLID))\n",
    "    \n",
    "#     count_ADS=0\n",
    "#     for k in range(len(ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID)):\n",
    "#         if ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[k]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[k]:\n",
    "#             count_ADS+=1\n",
    "    \n",
    "#     ADFS_5pc=float(float(count_ADS)/float(len(ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID)))\n",
    "    \n",
    "#     FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_conf.append(ADFS_conf)\n",
    "#     FRACTION_ANDERSON_DARLING_ALL_MODELS_SOLID_5pc.append(ADFS_5pc)\n",
    "    \n",
    "    \n",
    "    #work out the fraction of random tests for which the median distance is greater than\n",
    "    #in the sample distribution, i.e. sample points are closer to basal structures than\n",
    "    #random points\n",
    "    \n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_stat_two_sided.append(KSFS_stat_two_sided)\n",
    "    \n",
    "    \n",
    "    FRACTION_KOLMOGOROV_ALL_MODELS_SOLID_pval_two_sided.append(KSFS_pval_two_sided)\n",
    "\n",
    "\n",
    "    \n",
    "    #work out the fraction of random tests for which the median distance is greater than\n",
    "    #in the sample distribution, i.e. sample points are closer to basal structures than\n",
    "    #random points\n",
    "    \n",
    "    FRACTION_SMALLER_MEDIANS_SOLID=float(sum(abs(i) > abs(MEDIAN_MIN_SOLID_DISTANCE_DEG) for i in MEDIANS_ALL_RANDOM_SAMPLES_SOLID))/float(len(MEDIANS_ALL_RANDOM_SAMPLES_SOLID))\n",
    "   \n",
    "    FRACTION_SMALLER_MEDIANS_ALL_MODELS_SOLID.append(FRACTION_SMALLER_MEDIANS_SOLID)\n",
    "   \n",
    "    FRACTION_SMALLER_MEANS_SOLID = float(sum(i > MEAN_MIN_SOLID_DISTANCE_DEG for i in MEANS_ALL_RANDOM_SAMPLES_SOLID))/float(len(MEANS_ALL_RANDOM_SAMPLES_SOLID))\n",
    "   \n",
    "    FRACTION_SMALLER_MEANS_ALL_MODELS_SOLID.append(FRACTION_SMALLER_MEANS_SOLID)\n",
    "    \n",
    "    \n",
    "    countSmean=0 # \n",
    "#     countEmean=0\n",
    "    countSmedian=0\n",
    "    countSmeanWeak=0\n",
    "#     countEmedian=0\n",
    "    for l in range(nTests):\n",
    "        if MEANS_ALL_RANDOM_SAMPLES_SOLID[l] >= MEAN_MIN_SOLID_DISTANCE_DEG \\\n",
    "        and ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[l]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[l]:\n",
    "            countSmean+=1\n",
    "            \n",
    "        if ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[l]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[l]:\n",
    "            countSmeanWeak+=1    \n",
    "                \n",
    "        if abs(MEDIANS_ALL_RANDOM_SAMPLES_SOLID[l]) >= abs(MEDIAN_MIN_SOLID_DISTANCE_DEG) \\\n",
    "        and ANDERSON_DARLING_STAT_ALL_RANDOM_SAMPLES_SOLID[l]>ANDERSON_DARLING_FIVE_PERCENT_ALL_RANDOM_SAMPLES_SOLID[l]:\n",
    "            countSmedian+=1\n",
    "            \n",
    "    FRACTION_MEANS_AD_SOLID=float(float(countSmean)/float(nTests))\n",
    "    FRACTION_MEANS_AD_SOLIDWeak=float(float(countSmeanWeak)/float(nTests))\n",
    "    FRACTION_MEANS_AD_ALL_MODELS_SOLID.append(FRACTION_MEANS_AD_SOLID)\n",
    "\n",
    "    FRACTION_MEDIANS_AD_SOLID=float(float(countSmedian)/float(nTests))\n",
    "    FRACTION_MEDIANS_AD_ALL_MODELS_SOLID.append(FRACTION_MEDIANS_AD_SOLID)\n",
    "    \n",
    "#     print((100.0*float(countSmean)/nTests),' % of the time mean of the sample is less than random-Solid and Significantly Differs From Random')\n",
    "    \n",
    "    MEAN_MEDIANS_ALL_MODELS_SOLID.append(np.mean(np.array(MEDIANS_ALL_RANDOM_SAMPLES_SOLID),axis=0))\n",
    "    \n",
    "    #work out mean and median for the average of random samples for the solid case\n",
    "    MEAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    MEDIAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = []\n",
    "    \n",
    "    ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED=np.sort(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG, axis=-1,kind='stable')\n",
    "    MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.mean(np.array(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED),axis=0)\n",
    "\n",
    "#     below are the actual mim-max range\n",
    "    MIN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.amin(np.array(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED), axis=0)\n",
    "    MAX_MIN_RANDOM_SOLID_DISTANCE_DEG = np.amax(np.array(ALL_MIN_RANDOM_SOLID_DISTANCE_DEG_SORTED), axis=0)\n",
    "    \n",
    "    MEAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.mean(np.array(MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0)\n",
    "    MEDIAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG = np.median(np.array(MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG),axis=0)\n",
    "            \n",
    "    MEDIAN_ALL_MODELS_SOLID.append(MEDIAN_MIN_SOLID_DISTANCE_DEG)\n",
    "    MEDIAN_RANDOM_TEST_ALL_MODELS_SOLID.append(MEDIAN_MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n6, bins6, patches6 = ax.hist(MEAN_MIN_RANDOM_SOLID_DISTANCE_DEG, bins='fd', density=True, histtype='step',\n",
    "                            cumulative=True, label='Mean-Random', color='black', linewidth=3, zorder=4)\n",
    "    \n",
    "    patches6[0].set_xy(patches6[0].get_xy()[:-1])\n",
    "\n",
    "    \n",
    "    #plot the cumulative histogram\n",
    "#     a=np.asarray(MIN_SOLID_DISTANCE_DEG)\n",
    "    a=np.asarray(MIN_DISTANCE_HOT_DEG)\n",
    "    a=a.round(4)\n",
    "    \n",
    "    n7, bins7, patches7 = ax.hist(a, bins='fd', density=True, histtype='step',\n",
    "                            cumulative=True, label='SEMUCB-WM1-2867km', color='red', linewidth=3, zorder=5)\n",
    "        \n",
    "    patches7[0].set_xy(patches7[0].get_xy()[:-1])\n",
    "    \n",
    "    # tidy up the figure\n",
    "\n",
    "    #ax.grid(True)\n",
    "#     ax.grid()\n",
    "    ax.grid(zorder=0,linestyle='--', color='lightgrey')\n",
    "#     ax.legend(loc='lower right')\n",
    "    ax.set_xlim(0,15)\n",
    "    #ax.set_title('Cumulative step histograms')\n",
    "    ax.set_xlabel('Minimum angular distance ($\\degree$)')\n",
    "    ax.set_ylabel('Cumulative probability')\n",
    "#     ax.set_title('{:s} (Solid)'.format(model_case))\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "        r'Age= %i Ma' %(Age,),\n",
    "        r'n=%i' %(numKimbs,),\n",
    "        r'$\\overline{\\theta}_{Sample}=%.2f\\degree$' % (MEAN_MIN_SOLID_DISTANCE_DEG, ),\n",
    "        r'$\\overline{\\theta}_{Random}=%.2f\\degree$' %(np.mean(MEANS_ALL_RANDOM_SAMPLES_SOLID), ),\n",
    "        r'$f_{K-S}=%.2f$' %(KSFS_pval_two_sided),)) # based on pval.\n",
    "#         r'$f_{A-D}=%.2f$' %(ADFS_conf))) # 5 percent sig.\n",
    "\n",
    "\n",
    "#         r'${\\kappa}_{\\bar{\\theta}}=%.2f$' % (FRACTION_SMALLER_MEANS_SOLID, )))\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.80,edgecolor='lightgrey')\n",
    "    #ax.grid(True)\n",
    "#     ax.grid(zorder=0,linestyle='--', color='lightgrey')\n",
    "    # Create new legend handles but use the colors from the existing ones\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = [Line2D([], [], c=h.get_edgecolor()) for h in handles]\n",
    "    ax.legend(handles=new_handles[::-1], labels=labels[::-1], loc='lower left')\n",
    "    ax.text(0.65, 0.10, textstr, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='bottom', bbox=props)\n",
    " \n",
    "    ax.grid(zorder=1,linestyle='--', color='lightgrey')\n",
    "    \n",
    "    fig.savefig('/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/SEMUCB-WM1/2867km/SEMUCB-WM1-2867-km-'+str(Age)+'-Ma-180MaOnly.pdf', \n",
    "                bbox_inches='tight', dpi=600)\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    OutputDir=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/SEMUCB-WM1/Saved-Arrays\"\n",
    "    \n",
    "#     np.savetxt(OutputDir+'/SEMUCB-WM1-2867km-MIN-DISTANCES_'+str(Age)+'_Ma.txt',MIN_DISTANCE_HOT_DEG)\n",
    "\n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-MIN-DISTANCES-STD_'+str(Age)+'_Ma.npy',MIN_DISTANCE_HOT_DEG_STD)\n",
    "\n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-AD-Test-conf-5p-'+str(Age)+'_Ma.npy',ADFS_conf)\n",
    "\n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-AD-Test-conf-25p-'+str(Age)+'_Ma.npy',ADFS_conf_0_25)\n",
    "\n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-ks-stat-two-sided-'+str(Age)+'_Ma.npy',KSFS_stat_two_sided)\n",
    "    \n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-ks-stat-pval-'+str(Age)+'_Ma.npy',KSFS_pval_two_sided)\n",
    "   \n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-ks-stat-TwoCond-'+str(Age)+'_Ma.npy',FRACTION_KS_Crit_TwoCond)\n",
    "    \n",
    "#     np.save(OutputDir+'/SEMUCB-WM1-2867km-KS-Stat-critical-val'+str(Age)+'_Ma.npy',FRACTION_KS_Crit)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BaseD=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Flow-Model-Stats/\"\n",
    "Cases=[\"Case1\"]\n",
    "# Dpt=[\"UpperMantle\",\"LowerMantle\",\"WholeMantle\"]\n",
    "Dpt=[\"WholeMantle\"]\n",
    "\n",
    "Taki1=\"-MIN-DISTANCES_\"\n",
    "meanArray=[]\n",
    "\n",
    "Age=200\n",
    "# plt.gca()\n",
    "plt.close()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel('Age (Ma)')\n",
    "plt.ylabel('Mean distance ($\\degree$)')\n",
    "plt.grid(linewidth=0.3)\n",
    "plt.xticks(np.arange(200,20,-20))\n",
    "plt.gca().figure.dpi=200\n",
    "plt.ylim(0,25)\n",
    "\n",
    "# for tm in Cases:\n",
    "tm=\"Case1\"    \n",
    "    # plt.ylim(-5,105)\n",
    "    \n",
    "for d in Dpt: \n",
    "    if os.path.exists(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")==True:\n",
    "#             print(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        meanArray=[]\n",
    "        stdArray=[]\n",
    "#                 Ex=np.append(Ex,BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        for Age in np.arange(200,20,-20):\n",
    "            df = pd.read_csv(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\",\n",
    "                             skiprows=0,header=None,sep=',')\n",
    "            stdArray=np.append(stdArray,df.std()[0])\n",
    "            meanArray=np.append(meanArray,df.mean()[0])\n",
    "\n",
    "#             plt.plot(np.arange(200,20,-20),meanArray,label=tm+\"-\"+d)\n",
    "        ErLow=np.zeros(len(stdArray))\n",
    "        ErLowS=np.stack([ErLow,stdArray])\n",
    "        plt.errorbar(np.arange(200,20,-20),meanArray, yerr=ErLowS,label=tm+\"-\"+d)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#     plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "BaseD=\"/Users/omer/Desktop/NatGeoReviews/Statistical-Analysis/Tomographic-Model-Stats/\"\n",
    "tm=\"SEMUCB-WM1\"\n",
    "# Dpt=[\"2541km\",\"2867km\"]\n",
    "Dpt=[\"2867km\"]\n",
    "\n",
    "\n",
    "Taki1=\"-MIN-DISTANCES_\"\n",
    "meanArray=[]\n",
    "\n",
    "for d in Dpt: \n",
    "    if os.path.exists(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")==True:\n",
    "#             print(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        meanArray=[]\n",
    "        stdArray=[]\n",
    "#                 Ex=np.append(Ex,BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        for Age in np.arange(200,20,-20):\n",
    "            df = pd.read_csv(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\",\n",
    "                             skiprows=0,header=None,sep=',')\n",
    "            stdArray=np.append(stdArray,df.std()[0])\n",
    "            meanArray=np.append(meanArray,df.mean()[0])\n",
    "\n",
    "#             plt.plot(np.arange(200,20,-20),meanArray,label=tm+\"-\"+d)\n",
    "        ErLow=np.zeros(len(stdArray))\n",
    "        ErLowS=np.stack([ErLow,stdArray])\n",
    "        plt.errorbar(np.arange(200,20,-20),meanArray, yerr=ErLowS,label=tm+\"-\"+d)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "tm=\"GypsumS\"\n",
    "# Dpt=[\"2500km\",\"2900km\"]\n",
    "Dpt=[\"2900km\"]\n",
    "\n",
    "\n",
    "Taki1=\"-MIN-DISTANCES_\"\n",
    "# print()\n",
    "for d in Dpt: \n",
    "    if os.path.exists(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")==True:\n",
    "#             print(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        meanArray=[]\n",
    "        stdArray=[]\n",
    "#                 Ex=np.append(Ex,BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        for Age in np.arange(200,20,-20):\n",
    "            df = pd.read_csv(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\",\n",
    "                             skiprows=0,header=None,sep=',')\n",
    "            stdArray=np.append(stdArray,df.std()[0])\n",
    "            meanArray=np.append(meanArray,df.mean()[0])\n",
    "\n",
    "#             plt.plot(np.arange(200,20,-20),meanArray,label=tm+\"-\"+d)\n",
    "        ErLow=np.zeros(len(stdArray))\n",
    "        ErLowS=np.stack([ErLow,stdArray])\n",
    "        plt.errorbar(np.arange(200,20,-20),meanArray, yerr=ErLowS,label=tm+\"-\"+d)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm=\"Savani\"\n",
    "# Dpt=[\"2520km\",\"2818km\"]\n",
    "Dpt=[\"2818km\"]\n",
    "\n",
    "\n",
    "Taki1=\"-MIN-DISTANCES_\"\n",
    "for d in Dpt: \n",
    "    if os.path.exists(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")==True:\n",
    "#             print(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        meanArray=[]\n",
    "        stdArray=[]\n",
    "#                 Ex=np.append(Ex,BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        for Age in np.arange(200,20,-20):\n",
    "            df = pd.read_csv(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\",\n",
    "                             skiprows=0,header=None,sep=',')\n",
    "            stdArray=np.append(stdArray,df.std()[0])\n",
    "            meanArray=np.append(meanArray,df.mean()[0])\n",
    "\n",
    "#             plt.plot(np.arange(200,20,-20),meanArray,label=tm+\"-\"+d)\n",
    "        ErLow=np.zeros(len(stdArray))\n",
    "        ErLowS=np.stack([ErLow,stdArray])\n",
    "        plt.errorbar(np.arange(200,20,-20),meanArray, yerr=ErLowS,label=tm+\"-\"+d)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tm=\"s40rts\"\n",
    "# Dpt=[\"2514km\",\"2867km\"]\n",
    "Dpt=[\"2867km\"]\n",
    "\n",
    "\n",
    "Taki1=\"-MIN-DISTANCES_\"\n",
    "\n",
    "for d in Dpt: \n",
    "    if os.path.exists(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")==True:\n",
    "#             print(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        meanArray=[]\n",
    "        stdArray=[]\n",
    "#                 Ex=np.append(Ex,BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\")\n",
    "        for Age in np.arange(200,20,-20):\n",
    "            df = pd.read_csv(BaseD+tm+\"/Saved-Arrays/\"+tm+\"-\"+d+Taki1+str(Age)+\"_Ma.txt\",\n",
    "                             skiprows=0,header=None,sep=',')\n",
    "            stdArray=np.append(stdArray,df.std()[0])\n",
    "            meanArray=np.append(meanArray,df.mean()[0])\n",
    "\n",
    "#             plt.plot(np.arange(200,20,-20),meanArray,label=tm+\"-\"+d)\n",
    "        ErLow=np.zeros(len(stdArray))\n",
    "        ErLowS=np.stack([ErLow,stdArray])\n",
    "        plt.errorbar(np.arange(200,20,-20),meanArray, yerr=ErLowS,label=tm+\"-\"+d)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(fontsize=\"x-small\",loc=\"upper left\")\n",
    "#         plt.show()\n",
    "plt.savefig(\"Min-Distances-Case1-Vs-Tomos-Deep.pdf\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"Statistics-\"+tm+d+\"-Cases1-2-3-4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_pdist2hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRACTION_MEANS_AD_SOLID is the % that shorter distance and highly difference from random is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRACTION_MEANS_AD_SOLID,FRACTION_MEANS_AD_SOLIDWeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
